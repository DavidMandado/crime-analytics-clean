{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde886a4-1322-40dd-85ee-882cd19b1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# for cleaning text\n",
    "import re\n",
    "# for stopwords and tokenizing text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# reddit scraper\n",
    "import praw\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text analysis\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7e489-8797-40d8-850d-a93867b69ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"my id\",\n",
    "    client_secret=\"my secret\",\n",
    "    user_agent=\"my user agent\"\n",
    ")\n",
    "\n",
    "# Choose subreddits\n",
    "subreddits = [\n",
    "    \"london\", \"CasualUK\", \"ukcrime\",\n",
    "    \"AskUK\", \"ukpolitics\", \"BritishProblems\",\n",
    "    \"LegalAdviceUK\", \"policeuk\", \"ProtectAndServe\",\n",
    "    \"UKHousing\", \"UKLegalAdvice\"\n",
    "]\n",
    "\n",
    "# keywords to search for\n",
    "queries = [\n",
    "    \"burglary\", \"burgled\", \"break-in\", \"breaking and entering\", \n",
    "    \"home invasion\", \"house broken into\", \"theft\", \"stolen\", \"robbery\", \"robbed\", \n",
    "    \"property crime\", \"residential theft\", \"home security\", \"door locks\", \"window security\",\n",
    "    \"CCTV\", \"burglar alarm\", \"neighborhood watch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b809d0-2910-4f71-b775-c33be231eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores all posts\n",
    "results = []\n",
    "count = 0\n",
    "for query in queries:\n",
    "    for sub in subreddits:\n",
    "        # Searches for max 500 posts for each sub-query combination\n",
    "        for post in reddit.subreddit(sub).search(query, limit=500, sort=\"new\", time_filter=\"all\"):\n",
    "            data = {\n",
    "                \"title\": post.title,\n",
    "                \"selftext\": post.selftext,\n",
    "                \"author\": str(post.author),\n",
    "                \"score\": post.score,\n",
    "                \"url\": post.url,\n",
    "                \"created_utc\": post.created_utc,\n",
    "                \"num_comments\": post.num_comments,\n",
    "                \"id\": post.id,\n",
    "                \"permalink\": post.permalink,\n",
    "                \"subreddit\": str(post.subreddit),\n",
    "                \"matched_query\": query\n",
    "            }\n",
    "            results.append(data)\n",
    "        # for reddit timeout\n",
    "        time.sleep(1)\n",
    "    count += 1\n",
    "    print(f\"Queries left: {len(queries) - count}\", end='\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# store results in 'london_crime_posts.json'\n",
    "with open(\"london_crime_posts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(results)} posts to london_crime_posts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051acd9-fb55-4c2e-809a-85c75f74fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words to remove that are not important to the analysis\n",
    "more_stop_words = [\n",
    "    'im', 'ive', 'dont', 'know', 'new', 'want', 'got', 'day', 'said', 'really',\n",
    "    'like', 'time', 'london', 'uk', 'years', 'think', 'going', 'need', 'year',\n",
    "    'didnt', 'good', 'feel'\n",
    "]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(more_stop_words)\n",
    "\n",
    "# clean the text such that there are only relevant words left\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f148132-e198-4188-9e9a-9af9dbce9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the posts and drop duplicates\n",
    "posts = pd.read_json(\"london_crime_posts.json\")\n",
    "posts = posts.drop_duplicates(subset=\"id\", keep=\"first\").reset_index(drop=True)\n",
    "# append the body of the post to the title and clean it\n",
    "posts['full_text'] = (posts['title'].fillna('') + \" \" + posts['selftext'].fillna('')).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e541f-eaef-4283-9017-71869c096729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "def analyze_sentiment_dimensions(text):\n",
    "    blob = TextBlob(text.lower())\n",
    "    \n",
    "    # overall sentiment\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # trust related sentiment\n",
    "    trust_keywords = ['trust', 'reliable', 'dependable', 'honest', 'transparent']\n",
    "    distrust_keywords = ['distrust', 'unreliable', 'corrupt', 'biased', 'unfair']\n",
    "\n",
    "    # get trust related scores\n",
    "    trust_score = sum([text.lower().count(word) for word in trust_keywords])\n",
    "    distrust_score = sum([text.lower().count(word) for word in distrust_keywords])\n",
    "    \n",
    "    # effectiveness sentiment\n",
    "    effective_keywords = ['effective', 'helpful', 'successful', 'works', 'solved']\n",
    "    ineffective_keywords = ['ineffective', 'useless', 'failed', 'waste', 'pointless']\n",
    "\n",
    "    # effectiveness scores\n",
    "    effective_score = sum([text.lower().count(word) for word in effective_keywords])\n",
    "    ineffective_score = sum([text.lower().count(word) for word in ineffective_keywords])\n",
    "    \n",
    "    return {\n",
    "        'overall_sentiment': polarity,\n",
    "        'subjectivity': subjectivity,\n",
    "        'trust_net': trust_score - distrust_score,\n",
    "        'effectiveness_net': effective_score - ineffective_score\n",
    "    }\n",
    "\n",
    "# apply and add to posts DF\n",
    "sentiment_results = posts['full_text'].apply(analyze_sentiment_dimensions)\n",
    "sentiment_df = pd.DataFrame(sentiment_results.tolist())\n",
    "posts = pd.concat([posts, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f6da8-cbfd-4ee0-b7e1-99b9fba2bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictive policing attitude classification\n",
    "def classify_predictive_policing_attitude(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # pro-technology policing indicators\n",
    "    pro_tech = [\n",
    "        'data', 'algorithm', 'predict', 'prevent', 'technology', 'smart', \n",
    "        'efficient', 'evidence-based', 'statistics', 'analysis', 'pattern'\n",
    "    ]\n",
    "    \n",
    "    # anti-technology policing indicators\n",
    "    anti_tech = [\n",
    "        'surveillance', 'privacy', 'bias', 'discrimination', 'profiling',\n",
    "        'freedom', 'rights', 'civil liberties'\n",
    "    ]\n",
    "    \n",
    "    # community-focused policing indicators\n",
    "    community = [\n",
    "        'community', 'local', 'neighborhood', 'residents', 'engagement',\n",
    "        'dialogue', 'relationship', 'trust', 'human'\n",
    "    ]\n",
    "\n",
    "    # get all scores\n",
    "    pro_score = sum([text.count(word) for word in pro_tech])\n",
    "    anti_score = sum([text.count(word) for word in anti_tech])\n",
    "    community_score = sum([text.count(word) for word in community])\n",
    "\n",
    "    # return \n",
    "    if pro_score > anti_score and pro_score > community_score:\n",
    "        return 'pro_tech'\n",
    "    elif anti_score > pro_score and anti_score > community_score:\n",
    "        return 'anti_tech'\n",
    "    elif community_score > 0:\n",
    "        return 'community_focused'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# apply and add to posts DF\n",
    "posts['policing_attitude'] = posts['full_text'].apply(classify_predictive_policing_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf5695-a378-4dae-939c-82f5d9523a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concern categories for predictive policing (true or false for each category)\n",
    "def extract_concerns(text):\n",
    "    text = text.lower()\n",
    "    concerns = {}\n",
    "    \n",
    "    # privacy concerns\n",
    "    privacy_words = ['privacy', 'surveillance', 'monitoring', 'tracking', 'data collection']\n",
    "    concerns['privacy'] = any(word in text for word in privacy_words)\n",
    "    \n",
    "    # bias concerns\n",
    "    bias_words = ['bias', 'discrimination', 'racial', 'profiling', 'unfair', 'prejudice']\n",
    "    concerns['bias'] = any(word in text for word in bias_words)\n",
    "    \n",
    "    # accuracy concerns\n",
    "    accuracy_words = ['wrong', 'mistake', 'inaccurate', 'false positive', 'error']\n",
    "    concerns['accuracy'] = any(word in text for word in accuracy_words)\n",
    "    \n",
    "    # transparency concerns\n",
    "    transparency_words = ['black box', 'transparent', 'explain', 'understand', 'accountability']\n",
    "    concerns['transparency'] = any(word in text for word in transparency_words)\n",
    "    \n",
    "    # effectiveness concerns\n",
    "    effectiveness_words = ['waste', 'ineffective', 'doesn\\'t work', 'pointless', 'useless']\n",
    "    concerns['effectiveness'] = any(word in text for word in effectiveness_words)\n",
    "    \n",
    "    return concerns\n",
    "\n",
    "# apply to the text and add to posts DF\n",
    "concern_results = posts['full_text'].apply(extract_concerns)\n",
    "concern_df = pd.DataFrame(concern_results.tolist())\n",
    "posts = pd.concat([posts, concern_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f181e1a-4d90-4fcd-8421-24b34b28367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geographic insights\n",
    "def extract_location_mentions(text):\n",
    "    # london bouroughs\n",
    "    london_areas = [\n",
    "        'barking and dagenham', 'barnet', 'bexley', 'brent', 'bromley',\n",
    "        'camden', 'croydon', 'ealing', 'enfield', 'greenwich', 'hackney',\n",
    "        'hammersmith and fulham', 'haringey', 'harrow', 'havering', 'hillingdon',\n",
    "        'hounslow', 'islington', 'kensington and chelsea', 'kingston upon thames',\n",
    "        'lambeth', 'lewisham', 'merton', 'newham', 'redbridge', 'richmond upon thames',\n",
    "        'southwark', 'sutton', 'tower hamlets', 'waltham forest', 'wandsworth',\n",
    "        'westminster'\n",
    "    ]\n",
    "\n",
    "    # check if any of the locations were mentioned\n",
    "    text = text.lower()\n",
    "    mentioned_areas = [area for area in london_areas if area in text]\n",
    "    return mentioned_areas if mentioned_areas else ['general']\n",
    "\n",
    "# apply and add to posts DF\n",
    "posts['mentioned_areas'] = posts['full_text'].apply(extract_location_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fa165-0539-4845-8df6-696e2d11b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experience indicators\n",
    "def classify_experience_type(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # check what experience the poster had\n",
    "    if any(word in text for word in ['my house', 'my home', 'my flat', 'my apartment', 'i was', 'happened to me']):\n",
    "        return 'personal_victim'\n",
    "    elif any(word in text for word in ['neighbor', 'friend', 'family', 'colleague']):\n",
    "        return 'indirect_victim'\n",
    "    elif any(word in text for word in ['witnessed', 'saw', 'observed']):\n",
    "        return 'witness'\n",
    "    elif any(word in text for word in ['heard', 'read', 'news', 'report']):\n",
    "        return 'media_informed'\n",
    "    else:\n",
    "        return 'general_opinion'\n",
    "\n",
    "# apply and add to posts DF\n",
    "posts['experience_type'] = posts['full_text'].apply(classify_experience_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10badfbe-3561-4cd5-a040-4b295ee3c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full analysis\n",
    "def create_comprehensive_analysis():\n",
    "    print(\"Evaluation Analysis\\n\")\n",
    "    \n",
    "    # overall sentiment distribution\n",
    "    print(\"Overall sentiment towards policing:\")\n",
    "    print(f\"   Average sentiment: {posts['overall_sentiment'].mean():.3f}\")\n",
    "    print(f\"   Positive sentiment: {(posts['overall_sentiment'] > 0).sum()} posts ({(posts['overall_sentiment'] > 0).mean()*100:.1f}%)\")\n",
    "    print(f\"   Negative sentiment: {(posts['overall_sentiment'] < 0).sum()} posts ({(posts['overall_sentiment'] < 0).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # trust metrics\n",
    "    print(\"\\nTrust indicators:\")\n",
    "    print(f\"   Net trust score: {posts['trust_net'].mean():.3f}\")\n",
    "    trust_positive = (posts['trust_net'] > 0).sum()\n",
    "    trust_negative = (posts['trust_net'] < 0).sum()\n",
    "    print(f\"   Trust-positive posts: {trust_positive} ({trust_positive/len(posts)*100:.1f}%)\")\n",
    "    print(f\"   Trust-negative posts: {trust_negative} ({trust_negative/len(posts)*100:.1f}%)\")\n",
    "    \n",
    "    # predictive policing attitudes\n",
    "    print(\"\\nAttitudes towards predictive policing:\")\n",
    "    attitude_counts = posts['policing_attitude'].value_counts()\n",
    "    for attitude, count in attitude_counts.items():\n",
    "        print(f\"   {attitude}: {count} posts ({count/len(posts)*100:.1f}%)\")\n",
    "    \n",
    "    # main concerns\n",
    "    print(\"\\nMain concerns:\")\n",
    "    concern_cols = ['privacy', 'bias', 'accuracy', 'transparency', 'effectiveness']\n",
    "    for concern in concern_cols:\n",
    "        count = posts[concern].sum()\n",
    "        print(f\"   {concern.capitalize()}: {count} mentions ({count/len(posts)*100:.1f}%)\")\n",
    "    \n",
    "    # experience types\n",
    "    print(\"\\nExperience types:\")\n",
    "    exp_counts = posts['experience_type'].value_counts()\n",
    "    for exp_type, count in exp_counts.items():\n",
    "        print(f\"   {exp_type}: {count} posts ({count/len(posts)*100:.1f}%)\")\n",
    "    \n",
    "    # geographic distribution\n",
    "    print(\"\\nGeographic mentions:\")\n",
    "    all_areas = [area for areas in posts['mentioned_areas'] for area in areas]\n",
    "    area_counts = Counter(all_areas)\n",
    "    for area, count in area_counts.most_common(10):\n",
    "        print(f\"   {area}: {count} mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615fea6-e638-4ff4-8d1d-5b06cc2ad935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualizations\n",
    "def create_visualizations():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    axes[0,0].hist(posts['overall_sentiment'], bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[0,0].set_title('Overall Sentiment Distribution')\n",
    "    axes[0,0].set_xlabel('Sentiment Score')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Trust vs Effectiveness\n",
    "    axes[0,1].scatter(posts['trust_net'], posts['effectiveness_net'], alpha=0.6)\n",
    "    axes[0,1].set_title('Trust vs Effectiveness Perception')\n",
    "    axes[0,1].set_xlabel('Trust Net Score')\n",
    "    axes[0,1].set_ylabel('Effectiveness Net Score')\n",
    "    \n",
    "    # Policing attitudes\n",
    "    attitude_counts = posts['policing_attitude'].value_counts()\n",
    "    axes[0,2].pie(attitude_counts.values, labels=attitude_counts.index, autopct='%1.1f%%')\n",
    "    axes[0,2].set_title('Attitudes Toward Tech-Based Policing')\n",
    "    \n",
    "    # Concerns breakdown\n",
    "    concern_cols = ['privacy', 'bias', 'accuracy', 'transparency', 'effectiveness']\n",
    "    concern_counts = [posts[col].sum() for col in concern_cols]\n",
    "    axes[1,0].bar(concern_cols, concern_counts, color='lightcoral')\n",
    "    axes[1,0].set_title('Main Concerns About Predictive Policing')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Experience types\n",
    "    exp_counts = posts['experience_type'].value_counts()\n",
    "    axes[1,1].bar(exp_counts.index, exp_counts.values, color='lightgreen')\n",
    "    axes[1,1].set_title('Types of Crime Experience')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sentiment by experience type\n",
    "    sns.boxplot(data=posts, x='experience_type', y='overall_sentiment', ax=axes[1,2])\n",
    "    axes[1,2].set_title('Sentiment by Experience Type')\n",
    "    axes[1,2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3737a-5d78-4755-b833-6a4a67eb7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def export_analysis_ready_data():\n",
    "    \"\"\"Export processed data for further analysis\"\"\"\n",
    "    \n",
    "    # Create summary dataset\n",
    "    analysis_columns = [\n",
    "        'id', 'subreddit', 'score', 'num_comments', 'created_utc',\n",
    "        'overall_sentiment', 'subjectivity', 'trust_net', 'effectiveness_net',\n",
    "        'policing_attitude', 'experience_type', 'mentioned_areas',\n",
    "        'privacy', 'bias', 'accuracy', 'transparency', 'effectiveness'\n",
    "    ]\n",
    "    \n",
    "    analysis_df = posts[analysis_columns].copy()\n",
    "    analysis_df.to_csv('reddit_analysis_processed.csv', index=False)\n",
    "    \n",
    "    print(\"Processed data exported to 'reddit_analysis_processed.csv'\")\n",
    "    \n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cb71e-541c-48af-a658-d8ba547b5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_comprehensive_analysis()\n",
    "create_visualizations()\n",
    "processed_data = export_analysis_ready_data()\n",
    "\n",
    "print(f\"\\nAnalysis complete! Processed {len(posts)} posts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
