{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-27T08:31:16.859691Z",
     "start_time": "2025-05-27T08:31:16.843615Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import plotly.express as px"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:32:52.198523Z",
     "start_time": "2025-05-27T08:31:19.485898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_street = pd.read_csv(r'C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\combined_data_2019_onwards.csv', low_memory=False)\n",
    "df_street['Month'] = pd.to_datetime(df_street['Month'])\n",
    "df_street['year_month'] = df_street['Month'].dt.to_period('M')\n",
    "\n",
    "df_street.columns = df_street.columns.str.strip()\n",
    "target_crimes = [\n",
    "    'Anti-social behaviour', 'Bicycle theft', 'Criminal damage and arson',\n",
    "    'Drugs', 'Other crime', 'Other theft', 'Public order', 'Robbery',\n",
    "    'Shoplifting', 'Theft from the person', 'Vehicle crime', 'Burglary',\n",
    "    'Violence and sexual offences', 'Possession of weapons'\n",
    "]\n",
    "\n",
    "# Fi# Filter to relevant crimes\n",
    "filtered_df = df_street[df_street['Crime type'].isin(target_crimes)].copy()\n",
    "\n",
    "print(filtered_df.head())\n",
    "# Grouping keys\n",
    "group_keys = ['LSOA code', 'year_month']\n",
    "\n",
    "# For each crime type, add a column with counts per LSOA per month\n",
    "for crime in target_crimes:\n",
    "    crime_flag = (df_street['Crime type'] == crime).astype(int)\n",
    "    df_street[f'{crime}_count'] = (\n",
    "        df_street[group_keys].join(crime_flag).groupby(group_keys).transform('sum')\n",
    "    )\n",
    "\n",
    "# Optional total\n",
    "df_street['total_target_crimes'] = df_street[[f'{c}_count' for c in target_crimes]].sum(axis=1)\n",
    "\n",
    "# Optional: burglary flag (if needed for downstream aggregation)\n",
    "df_street['is_burglary'] = (df_street['Crime type'] == 'Burglary').astype(int)\n",
    "\n",
    "# View result\n",
    "print(df_street.head())\n",
    "\n",
    "\n",
    "# useful for later\n",
    "lsoa_lookup = df_street[['Latitude', 'Longitude', 'LSOA name']].drop_duplicates()\n",
    "\n",
    "\n",
    "# Build lookup from original street data\n",
    "lsoa_code_name_lookup = df_street[['LSOA name', 'LSOA code']].drop_duplicates()\n",
    "\n",
    "# aggregation of street data\n",
    "burglary_agg = df_street.groupby(['LSOA name', 'year_month'])\n",
    "\"\"\"\n",
    "                .agg(\n",
    "    total_crimes=('Crime ID', 'count'),\n",
    "    burglaries=('is_burglary', 'sum')\n",
    ").reset_index())\n",
    "\"\"\"\n",
    "#stop and seach time\n",
    "df_stopsearch = pd.read_csv(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Tenzing's work folder\\combined_data_S&S_2019_onwaresd.csv\", low_memory=False)\n",
    "df_stopsearch['Date'] = pd.to_datetime(df_stopsearch['Date'])\n",
    "df_stopsearch['year_month'] = df_stopsearch['Date'].dt.to_period('M')\n",
    "\n",
    "# spatial join to add LSOA names\n",
    "df_stopsearch_lsoa = pd.merge(\n",
    "    df_street,\n",
    "    lsoa_lookup,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Aggregate stop and search data per LSOA and month\n",
    "#stopsearch_agg_lsoa = df_stopsearch_lsoa.groupby(['LSOA name', 'year_month']).size().reset_index(name='stop_search_count')\n",
    "\n",
    "\n",
    "# Merge burglary and stop & search data into one main df\n",
    "combined_df = pd.merge(\n",
    "    df_street,\n",
    "    df_stopsearch_lsoa,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "combined_df['stop_search_count'] = combined_df['stop_search_count'].fillna(0)\n",
    "\n",
    "\n",
    "new_data_df = pd.read_csv(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Data\\crime_counts_with_lags_imd_and_population.csv\")\n",
    "print(new_data_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Parse month as datetime and convert to Period[M] to match main dataset\n",
    "new_data_df['month'] = pd.to_datetime(new_data_df['month']).dt.to_period('M')\n",
    "\n",
    "# Focus on burglary only\n",
    "new_data_df = new_data_df[new_data_df['crime_type'].str.lower() == 'burglary']\n",
    "\n",
    "\n",
    "# Merge engineered features into combined_df\n",
    "combined_df = pd.merge(\n",
    "    combined_df,\n",
    "    lsoa_code_name_lookup,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 4. Now merge with lag/IMD/population features\n",
    "combined_df = pd.merge(\n",
    "    combined_df,\n",
    "    new_data_df,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# idk if I should split year_month (potential seasonality features)\n",
    "combined_df['year'] = combined_df['year_month'].dt.year\n",
    "combined_df['month'] = combined_df['year_month'].dt.month\n",
    "combined_df.groupby(['lsoa_code', 'year', 'month'])"
   ],
   "id": "6029085c83991b7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Crime ID      Month  \\\n",
      "0  a8977a2a4e14252420371eb993d52e4d0b8288a7c833e6... 2019-01-01   \n",
      "1                                                NaN 2019-01-01   \n",
      "2  934e173f2bc2e1dd3a257b37939d8f97575d3eeb89ff0c... 2019-01-01   \n",
      "3  4f5b7e424bc78b1fb8c32e07da61176d2cbc5a3849d8e1... 2019-01-01   \n",
      "4  53d960600a4a9f54b785f598af4c75bdef2f79bce1a41b... 2019-01-01   \n",
      "\n",
      "                   Reported by                 Falls within  Longitude  \\\n",
      "0  Metropolitan Police Service  Metropolitan Police Service  -0.709911   \n",
      "1  Metropolitan Police Service  Metropolitan Police Service   0.140192   \n",
      "2  Metropolitan Police Service  Metropolitan Police Service   0.140192   \n",
      "3  Metropolitan Police Service  Metropolitan Police Service   0.140634   \n",
      "4  Metropolitan Police Service  Metropolitan Police Service   0.141143   \n",
      "\n",
      "    Latitude                     Location  LSOA code  \\\n",
      "0  50.784615     On or near Rochester Way  E01031384   \n",
      "1  51.582311       On or near Hatch Grove  E01000027   \n",
      "2  51.582311       On or near Hatch Grove  E01000027   \n",
      "3  51.583427        On or near Rams Grove  E01000027   \n",
      "4  51.590873  On or near Furze Farm Close  E01000027   \n",
      "\n",
      "                   LSOA name                    Crime type  \\\n",
      "0                  Arun 018E  Violence and sexual offences   \n",
      "1  Barking and Dagenham 001A         Anti-social behaviour   \n",
      "2  Barking and Dagenham 001A                      Burglary   \n",
      "3  Barking and Dagenham 001A                      Burglary   \n",
      "4  Barking and Dagenham 001A                         Drugs   \n",
      "\n",
      "  Last outcome category  Context                      source_file year_month  \n",
      "0   Under investigation      NaN  2019-01-metropolitan-street.csv    2019-01  \n",
      "1                   NaN      NaN  2019-01-metropolitan-street.csv    2019-01  \n",
      "2   Under investigation      NaN  2019-01-metropolitan-street.csv    2019-01  \n",
      "3   Under investigation      NaN  2019-01-metropolitan-street.csv    2019-01  \n",
      "4   Under investigation      NaN  2019-01-metropolitan-street.csv    2019-01  \n",
      "                                            Crime ID      Month  \\\n",
      "0  a8977a2a4e14252420371eb993d52e4d0b8288a7c833e6... 2019-01-01   \n",
      "1                                                NaN 2019-01-01   \n",
      "2  934e173f2bc2e1dd3a257b37939d8f97575d3eeb89ff0c... 2019-01-01   \n",
      "3  4f5b7e424bc78b1fb8c32e07da61176d2cbc5a3849d8e1... 2019-01-01   \n",
      "4  53d960600a4a9f54b785f598af4c75bdef2f79bce1a41b... 2019-01-01   \n",
      "\n",
      "                   Reported by                 Falls within  Longitude  \\\n",
      "0  Metropolitan Police Service  Metropolitan Police Service  -0.709911   \n",
      "1  Metropolitan Police Service  Metropolitan Police Service   0.140192   \n",
      "2  Metropolitan Police Service  Metropolitan Police Service   0.140192   \n",
      "3  Metropolitan Police Service  Metropolitan Police Service   0.140634   \n",
      "4  Metropolitan Police Service  Metropolitan Police Service   0.141143   \n",
      "\n",
      "    Latitude                     Location  LSOA code  \\\n",
      "0  50.784615     On or near Rochester Way  E01031384   \n",
      "1  51.582311       On or near Hatch Grove  E01000027   \n",
      "2  51.582311       On or near Hatch Grove  E01000027   \n",
      "3  51.583427        On or near Rams Grove  E01000027   \n",
      "4  51.590873  On or near Furze Farm Close  E01000027   \n",
      "\n",
      "                   LSOA name                    Crime type  ...  \\\n",
      "0                  Arun 018E  Violence and sexual offences  ...   \n",
      "1  Barking and Dagenham 001A         Anti-social behaviour  ...   \n",
      "2  Barking and Dagenham 001A                      Burglary  ...   \n",
      "3  Barking and Dagenham 001A                      Burglary  ...   \n",
      "4  Barking and Dagenham 001A                         Drugs  ...   \n",
      "\n",
      "  Public order_count  Robbery_count Shoplifting_count  \\\n",
      "0                0.0            0.0               0.0   \n",
      "1                0.0            0.0               0.0   \n",
      "2                0.0            0.0               0.0   \n",
      "3                0.0            0.0               0.0   \n",
      "4                0.0            0.0               0.0   \n",
      "\n",
      "  Theft from the person_count  Vehicle crime_count  Burglary_count  \\\n",
      "0                         0.0                  0.0             0.0   \n",
      "1                         0.0                  4.0             2.0   \n",
      "2                         0.0                  4.0             2.0   \n",
      "3                         0.0                  4.0             2.0   \n",
      "4                         0.0                  4.0             2.0   \n",
      "\n",
      "   Violence and sexual offences_count  Possession of weapons_count  \\\n",
      "0                                 1.0                          0.0   \n",
      "1                                 4.0                          0.0   \n",
      "2                                 4.0                          0.0   \n",
      "3                                 4.0                          0.0   \n",
      "4                                 4.0                          0.0   \n",
      "\n",
      "   total_target_crimes  is_burglary  \n",
      "0                  1.0            0  \n",
      "1                 14.0            0  \n",
      "2                 14.0            1  \n",
      "3                 14.0            1  \n",
      "4                 14.0            0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgshe\\AppData\\Local\\Temp\\ipykernel_4428\\2165158342.py:55: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_stopsearch['year_month'] = df_stopsearch['Date'].dt.to_period('M')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'stop_search_count'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'stop_search_count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 76\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Aggregate stop and search data per LSOA and month\u001B[39;00m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;66;03m#stopsearch_agg_lsoa = df_stopsearch_lsoa.groupby(['LSOA name', 'year_month']).size().reset_index(name='stop_search_count')\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \n\u001B[0;32m     68\u001B[0m \n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# Merge burglary and stop & search data into one main df\u001B[39;00m\n\u001B[0;32m     70\u001B[0m combined_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(\n\u001B[0;32m     71\u001B[0m     df_street,\n\u001B[0;32m     72\u001B[0m     df_stopsearch_lsoa,\n\u001B[0;32m     73\u001B[0m     how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     74\u001B[0m )\n\u001B[1;32m---> 76\u001B[0m combined_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstop_search_count\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mcombined_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstop_search_count\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     79\u001B[0m new_data_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmgshe\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mPycharmProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mAddressing-real-world-crime-and-security-problems-with-data-science\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcrime_counts_with_lags_imd_and_population.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28mprint\u001B[39m(new_data_df\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'stop_search_count'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:32:52.480599700Z",
     "start_time": "2025-05-27T08:06:50.285292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lsoas = gpd.read_file(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Tenzing's work folder\\LSOAs.geojson\").to_crs(epsg=4326)\n",
    "lsoas = (\n",
    "    lsoas[lsoas['LAD11NM'] != 'City of London']\n",
    "    [['LSOA11CD','geometry']]\n",
    "    .rename(columns={'LSOA11CD':'lsoa_code'})\n",
    ")\n",
    "\n",
    "data = combined_df\n"
   ],
   "id": "aa647450266fdc49",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:09:53.661743Z",
     "start_time": "2025-05-27T08:09:53.649720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "burglary_agg.head()\n",
    "#data.head()"
   ],
   "id": "76086780373eef20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   LSOA name year_month  total_crimes  burglaries\n",
       "0  Adur 001B    2020-10             1           0\n",
       "1  Adur 001C    2021-10             1           0\n",
       "2  Adur 001E    2022-06             1           0\n",
       "3  Adur 003A    2022-05             1           0\n",
       "4  Adur 003D    2021-07             1           0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>total_crimes</th>\n",
       "      <th>burglaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adur 001B</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adur 001C</td>\n",
       "      <td>2021-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adur 001E</td>\n",
       "      <td>2022-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adur 003A</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adur 003D</td>\n",
       "      <td>2021-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:06:55.700591Z",
     "start_time": "2025-05-27T08:06:55.674518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Per-LSOA temporal split\n",
    "def lsoa_wise_temporal_split(df, test_months=3):\n",
    "    train_list, test_list = [], []\n",
    "    # for each lsoa and its subdf group\n",
    "    for lsoa, group in df.groupby('lsoa_code'):\n",
    "        group = group.sort_values('month')\n",
    "        # if the lsoa has less than or equal to amount of test months always put in train list\n",
    "        if group.shape[0] <= test_months:\n",
    "            train_list.append(group)\n",
    "        # else there is enough data, so add all but last test_months rows to training\n",
    "        # add last test_months rows to test\n",
    "        else:\n",
    "            train_list.append(group.iloc[:-test_months])\n",
    "            test_list.append(group.iloc[-test_months:])\n",
    "    # convert into dfs\n",
    "    train_df = pd.concat(train_list)\n",
    "    test_df = pd.concat(test_list)\n",
    "    return train_df, test_df"
   ],
   "id": "75190c9465738fd3",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:08:18.748029Z",
     "start_time": "2025-05-27T08:08:13.718827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# independent variables\n",
    "features = [\n",
    "    'rolling_std_3','rolling_mean_6','rolling_sum_12',\n",
    "    'Anti-social behaviour_count', 'Bicycle theft_count', 'Criminal damage and arson_count',\n",
    "    'Drugs_count', 'Other crime_count', 'Other theft_count',\n",
    "    'Public order_count', 'Robbery_count', 'Shoplifting_count', 'Theft from the person_count',\n",
    "    'Vehicle crime_count', 'Violence and sexual offences_count',\n",
    "    'Possession of weapons_count', 'rolling_mean_3','health_decile_2019',\n",
    "    'lag_1','lag_2','lag_3','imd_decile_2019','income_decile_2019','employment_decile_2019',\n",
    "    'crime_decile_2019','total_crimes', 'stop_search_count', 'year', 'month'\n",
    "]\n",
    "\n",
    "# get train and test dfs\n",
    "train_df, test_df = lsoa_wise_temporal_split(data, test_months=3)\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[['target_1','target_2','target_3']]\n",
    "X_test  = test_df[features]\n",
    "y_test  = test_df[['target_1','target_2','target_3']]"
   ],
   "id": "3b8381f575d03195",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 111486, Test rows: 14559\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Anti-social behaviour_count', 'Bicycle theft_count', 'Criminal damage and arson_count', 'Drugs_count', 'Other crime_count', 'Other theft_count', 'Public order_count', 'Robbery_count', 'Shoplifting_count', 'Theft from the person_count', 'Vehicle crime_count', 'Violence and sexual offences_count', 'Possession of weapons_count'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m train_df, test_df \u001B[38;5;241m=\u001B[39m lsoa_wise_temporal_split(data, test_months\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain rows: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test rows: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(test_df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 17\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     18\u001B[0m y_train \u001B[38;5;241m=\u001B[39m train_df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_1\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_2\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_3\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m     19\u001B[0m X_test  \u001B[38;5;241m=\u001B[39m test_df[features]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   4107\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 4108\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   4110\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Anti-social behaviour_count', 'Bicycle theft_count', 'Criminal damage and arson_count', 'Drugs_count', 'Other crime_count', 'Other theft_count', 'Public order_count', 'Robbery_count', 'Shoplifting_count', 'Theft from the person_count', 'Vehicle crime_count', 'Violence and sexual offences_count', 'Possession of weapons_count'] not in index\""
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "# gradient boost models\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ],
   "id": "f63f94f76c2f683"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# list of regressors to test\n",
    "regressors = {\n",
    "    'LightGBM': LGBMRegressor(n_estimators=300, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=300, random_state=42, verbosity=0),\n",
    "    'Random_Forest': RandomForestRegressor(n_estimators=100, random_state=42, verbose=False),\n",
    "    'cat': CatBoostRegressor(iterations=300, learning_rate=0.1, random_state=42, verbose=False),\n",
    "    'ada': AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=3), n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "}\n",
    "\n",
    "# change to choose model\n",
    "name = 'LightGBM'\n",
    "\n",
    "# regressors by themselves predicts one month ahead,\n",
    "# so MultiOutputRegressor allows to predict multiple (all three targets)\n",
    "rf = MultiOutputRegressor(regressors[name])\n",
    "\n",
    "t0 = time.perf_counter()    # timer for fitting\n",
    "rf.fit(X_train, y_train)\n",
    "fit_time = time.perf_counter() - t0\n",
    "\n",
    "print(f'Regressor: {name}')\n",
    "print(f'Fit time: {fit_time:.2f} seconds')\n",
    "\n",
    "# get predictions for three months into the future\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# print rmse and r^2 for all three months in future\n",
    "horizons = ['1‑month ahead', '2‑months ahead', '3‑months ahead']\n",
    "for i, title in enumerate(horizons):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.values[:,i], y_pred[:,i]))\n",
    "    r2   = r2_score(y_test.values[:,i], y_pred[:,i])\n",
    "    print(f'{title}: RMSE={rmse:.2f}, R²={r2:.3f}')"
   ],
   "id": "252f1e9ce6b9dc85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# show feature importances\n",
    "importances = np.mean([est.feature_importances_ for est in rf.estimators_], axis=0)\n",
    "imp_df = pd.DataFrame({'feature': features, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "print(imp_df)"
   ],
   "id": "7eb895481982f590"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CREATE VISUALIZATION\n",
    "vis_df = test_df.copy()\n",
    "vis_df[['pred_1', 'pred_2', 'pred_3']] = y_pred\n",
    "\n",
    "# get the predictions from the latest months so that future months are shown\n",
    "month = 3\n",
    "latest_preds = (\n",
    "    vis_df.sort_values('month')\n",
    "           .groupby('lsoa_code')\n",
    "           .tail(1)[['lsoa_code', f'pred_{month}']]\n",
    "           .rename(columns={f'pred_{month}': 'predicted_burglaries'})\n",
    ")\n",
    "\n",
    "latest_preds.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge predictions with GeoData\n",
    "geo = lsoas.merge(latest_preds, on='lsoa_code', how='inner')\n",
    "\n",
    "# Convert to JSON\n",
    "geojson = json.loads(geo.to_json())\n",
    "\n",
    "# Plot choropleth (works in Jupyter)\n",
    "fig = px.choropleth_map(\n",
    "    geo,\n",
    "    geojson=geojson,\n",
    "    locations='lsoa_code',\n",
    "    featureidkey=\"properties.lsoa_code\",\n",
    "    color='predicted_burglaries',\n",
    "    range_color=(0, geo['predicted_burglaries'].max()),\n",
    "    color_continuous_scale=\"OrRd\",\n",
    "    map_style=\"open-street-map\",\n",
    "    zoom=9,\n",
    "    center={\"lat\": 51.5072, \"lon\": -0.1276},\n",
    "    opacity=0.6,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(title=f'Predicted Burglary Count using {name} ({month}-month horizon) by LSOA')\n",
    "fig.show()"
   ],
   "id": "daaddde041a0e7e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
