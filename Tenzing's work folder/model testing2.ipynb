{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:32:56.540984Z",
     "start_time": "2025-05-27T08:32:56.472974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import plotly.express as px"
   ],
   "id": "9ebaab9cffdc1534",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:33:23.639305Z",
     "start_time": "2025-05-27T08:32:57.850636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#streed data\n",
    "df_street = pd.read_csv(r'C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\combined_data_2019_onwards.csv', low_memory=False)\n",
    "df_street['Month'] = pd.to_datetime(df_street['Month'])\n",
    "df_street['year_month'] = df_street['Month'].dt.to_period('M')\n",
    "\n",
    "# useful for later\n",
    "lsoa_lookup = df_street[['Latitude', 'Longitude', 'LSOA name']].drop_duplicates()\n",
    "\n",
    "\n",
    "# Build lookup from original street data\n",
    "lsoa_code_name_lookup = df_street[['LSOA name', 'LSOA code']].drop_duplicates()\n",
    "\n",
    "# burglary flag\n",
    "df_street['is_burglary'] = (df_street['Crime type'].str.lower() == 'burglary').astype(int)\n",
    "\n",
    "# aggregation of street data\n",
    "burglary_agg = df_street.groupby(['LSOA name', 'year_month']).agg(\n",
    "    total_crimes=('Crime ID', 'count'),\n",
    "    burglaries=('is_burglary', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "#stop and seach time\n",
    "df_stopsearch = pd.read_csv(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Tenzing's work folder\\combined_data_S&S_2019_onwaresd.csv\", low_memory=False)\n",
    "df_stopsearch['Date'] = pd.to_datetime(df_stopsearch['Date'])\n",
    "df_stopsearch['year_month'] = df_stopsearch['Date'].dt.to_period('M')\n",
    "\n",
    "# spatial join to add LSOA names\n",
    "df_stopsearch_lsoa = pd.merge(\n",
    "    df_stopsearch,\n",
    "    lsoa_lookup,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Aggregate stop and search data per LSOA and month\n",
    "stopsearch_agg_lsoa = df_stopsearch_lsoa.groupby(['LSOA name', 'year_month']).size().reset_index(name='stop_search_count')\n",
    "\n",
    "\n",
    "# Merge burglary and stop & search data into one main df\n",
    "combined_df = pd.merge(\n",
    "    burglary_agg,\n",
    "    stopsearch_agg_lsoa,\n",
    "    on=['LSOA name', 'year_month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "combined_df['stop_search_count'] = combined_df['stop_search_count'].fillna(0)\n",
    "\n",
    "\n",
    "new_data_df = pd.read_csv(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Data\\crime_counts_with_lags_imd_and_population.csv\")\n",
    "print(new_data_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Parse month as datetime and convert to Period[M] to match main dataset\n",
    "new_data_df['month'] = pd.to_datetime(new_data_df['month']).dt.to_period('M')\n",
    "\n",
    "# Focus on burglary only\n",
    "new_data_df = new_data_df[new_data_df['crime_type'].str.lower() == 'burglary']\n",
    "\n",
    "\n",
    "# Merge engineered features into combined_df\n",
    "combined_df = pd.merge(\n",
    "    combined_df,\n",
    "    lsoa_code_name_lookup,\n",
    "    on='LSOA name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 4. Now merge with lag/IMD/population features\n",
    "combined_df = pd.merge(\n",
    "    combined_df,\n",
    "    new_data_df,\n",
    "    left_on=['LSOA code', 'year_month'],\n",
    "    right_on=['lsoa_code', 'month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# idk if I should split year_month (potential seasonality features)\n",
    "combined_df['year'] = combined_df['year_month'].dt.year\n",
    "combined_df['month'] = combined_df['year_month'].dt.month"
   ],
   "id": "4def3c505623e9bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgshe\\AppData\\Local\\Temp\\ipykernel_4408\\311636465.py:25: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_stopsearch['year_month'] = df_stopsearch['Date'].dt.to_period('M')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lsoa_code       month             crime_type  crime_count  lag_1  lag_2  \\\n",
      "0  E01000001  2024-11-01  Anti-social behaviour            1    1.0    1.0   \n",
      "1  E01000001  2024-12-01  Anti-social behaviour            1    1.0    1.0   \n",
      "2  E01000001  2021-09-01            Other theft            1    1.0    1.0   \n",
      "3  E01000001  2021-12-01            Other theft            1    1.0    1.0   \n",
      "4  E01000001  2022-03-01            Other theft            3    1.0    1.0   \n",
      "\n",
      "   lag_3  rolling_mean_3  rolling_std_3  rolling_mean_6  rolling_sum_12  \\\n",
      "0    1.0        1.000000        0.00000        1.000000            12.0   \n",
      "1    1.0        1.000000        0.00000        1.000000            12.0   \n",
      "2    2.0        1.333333        0.57735        1.333333            19.0   \n",
      "3    1.0        1.000000        0.00000        1.166667            19.0   \n",
      "4    1.0        1.000000        0.00000        1.166667            17.0   \n",
      "\n",
      "   imd_decile_2019  income_decile_2019  employment_decile_2019  \\\n",
      "0              9.0                10.0                    10.0   \n",
      "1              9.0                10.0                    10.0   \n",
      "2              9.0                10.0                    10.0   \n",
      "3              9.0                10.0                    10.0   \n",
      "4              9.0                10.0                    10.0   \n",
      "\n",
      "   crime_decile_2019  health_decile_2019  population  crimes_per_1000  \n",
      "0               10.0                10.0       1.573       635.727908  \n",
      "1               10.0                10.0       1.573       635.727908  \n",
      "2               10.0                10.0       1.573       635.727908  \n",
      "3               10.0                10.0       1.573       635.727908  \n",
      "4               10.0                10.0       1.573      1907.183725  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:33:33.201416Z",
     "start_time": "2025-05-27T08:33:31.433219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lsoas = gpd.read_file(r\"C:\\Users\\mgshe\\PycharmProjects\\Addressing-real-world-crime-and-security-problems-with-data-science\\Tenzing's work folder\\LSOAs.geojson\").to_crs(epsg=4326)\n",
    "lsoas = (\n",
    "    lsoas[lsoas['LAD11NM'] != 'City of London']\n",
    "    [['LSOA11CD','geometry']]\n",
    "    .rename(columns={'LSOA11CD':'lsoa_code'})\n",
    ")\n",
    "\n",
    "data = combined_df"
   ],
   "id": "267a6dca61d8641f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:33:50.001347Z",
     "start_time": "2025-05-27T08:33:49.982349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Per-LSOA temporal split\n",
    "def lsoa_wise_temporal_split(df, test_months=3):\n",
    "    train_list, test_list = [], []\n",
    "    # for each lsoa and its subdf group\n",
    "    for lsoa, group in df.groupby('lsoa_code'):\n",
    "        group = group.sort_values('month')\n",
    "        # if the lsoa has less than or equal to amount of test months always put in train list\n",
    "        if group.shape[0] <= test_months:\n",
    "            train_list.append(group)\n",
    "        # else there is enough data, so add all but last test_months rows to training\n",
    "        # add last test_months rows to test\n",
    "        else:\n",
    "            train_list.append(group.iloc[:-test_months])\n",
    "            test_list.append(group.iloc[-test_months:])\n",
    "    # convert into dfs\n",
    "    train_df = pd.concat(train_list)\n",
    "    test_df = pd.concat(test_list)\n",
    "    return train_df, test_df"
   ],
   "id": "543f4f4b11110207",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:33:55.879899Z",
     "start_time": "2025-05-27T08:33:52.582444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# independent variables\n",
    "features = [\n",
    "    'rolling_std_3','rolling_mean_6','rolling_sum_12', 'rolling_mean_3','health_decile_2019',\n",
    "    'lag_1','lag_2','lag_3','imd_decile_2019','income_decile_2019','employment_decile_2019',\n",
    "    'crime_decile_2019','total_crimes', 'stop_search_count', 'year', 'month'\n",
    "]\n",
    "\n",
    "# get train and test dfs\n",
    "train_df, test_df = lsoa_wise_temporal_split(data, test_months=3)\n",
    "print(f\"Train rows: {len(train_df)}, Test rows: {len(test_df)}\")\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[['target_1','target_2','target_3']]\n",
    "X_test  = test_df[features]\n",
    "y_test  = test_df[['target_1','target_2','target_3']]"
   ],
   "id": "cce3cd9c850583e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 111486, Test rows: 14559\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['target_1', 'target_2', 'target_3'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain rows: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test rows: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(test_df)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m X_train \u001B[38;5;241m=\u001B[39m train_df[features]\n\u001B[1;32m---> 13\u001B[0m y_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget_1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget_2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtarget_3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     14\u001B[0m X_test  \u001B[38;5;241m=\u001B[39m test_df[features]\n\u001B[0;32m     15\u001B[0m y_test  \u001B[38;5;241m=\u001B[39m test_df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_1\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_2\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_3\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   4107\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 4108\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   4110\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nmissing:\n\u001B[0;32m   6248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m nmissing \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(indexer):\n\u001B[1;32m-> 6249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m     not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   6252\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['target_1', 'target_2', 'target_3'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "# gradient boost models\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ],
   "id": "60518d645f3f241d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# list of regressors to test\n",
    "regressors = {\n",
    "    'LightGBM': LGBMRegressor(n_estimators=300, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=300, random_state=42, verbosity=0),\n",
    "    'Random_Forest': RandomForestRegressor(n_estimators=100, random_state=42, verbose=False),\n",
    "    'cat': CatBoostRegressor(iterations=300, learning_rate=0.1, random_state=42, verbose=False),\n",
    "    'ada': AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=3), n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "}\n",
    "\n",
    "# change to choose model\n",
    "name = 'LightGBM'\n",
    "\n",
    "# regressors by themselves predicts one month ahead,\n",
    "# so MultiOutputRegressor allows to predict multiple (all three targets)\n",
    "rf = MultiOutputRegressor(regressors[name])\n",
    "\n",
    "t0 = time.perf_counter()    # timer for fitting\n",
    "rf.fit(X_train, y_train)\n",
    "fit_time = time.perf_counter() - t0\n",
    "\n",
    "print(f'Regressor: {name}')\n",
    "print(f'Fit time: {fit_time:.2f} seconds')\n",
    "\n",
    "# get predictions for three months into the future\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# print rmse and r^2 for all three months in future\n",
    "horizons = ['1‑month ahead', '2‑months ahead', '3‑months ahead']\n",
    "for i, title in enumerate(horizons):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.values[:,i], y_pred[:,i]))\n",
    "    r2   = r2_score(y_test.values[:,i], y_pred[:,i])\n",
    "    print(f'{title}: RMSE={rmse:.2f}, R²={r2:.3f}')"
   ],
   "id": "91e4e9e493c2245e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# show feature importances\n",
    "importances = np.mean([est.feature_importances_ for est in rf.estimators_], axis=0)\n",
    "imp_df = pd.DataFrame({'feature': features, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "print(imp_df)"
   ],
   "id": "4df9acd117d8f747"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CREATE VISUALIZATION\n",
    "vis_df = test_df.copy()\n",
    "vis_df[['pred_1', 'pred_2', 'pred_3']] = y_pred\n",
    "\n",
    "# get the predictions from the latest months so that future months are shown\n",
    "month = 3\n",
    "latest_preds = (\n",
    "    vis_df.sort_values('month')\n",
    "           .groupby('lsoa_code')\n",
    "           .tail(1)[['lsoa_code', f'pred_{month}']]\n",
    "           .rename(columns={f'pred_{month}': 'predicted_burglaries'})\n",
    ")\n",
    "\n",
    "latest_preds.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge predictions with GeoData\n",
    "geo = lsoas.merge(latest_preds, on='lsoa_code', how='inner')\n",
    "\n",
    "# Convert to JSON\n",
    "geojson = json.loads(geo.to_json())\n",
    "\n",
    "# Plot choropleth (works in Jupyter)\n",
    "fig = px.choropleth_map(\n",
    "    geo,\n",
    "    geojson=geojson,\n",
    "    locations='lsoa_code',\n",
    "    featureidkey=\"properties.lsoa_code\",\n",
    "    color='predicted_burglaries',\n",
    "    range_color=(0, geo['predicted_burglaries'].max()),\n",
    "    color_continuous_scale=\"OrRd\",\n",
    "    map_style=\"open-street-map\",\n",
    "    zoom=9,\n",
    "    center={\"lat\": 51.5072, \"lon\": -0.1276},\n",
    "    opacity=0.6,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(title=f'Predicted Burglary Count using {name} ({month}-month horizon) by LSOA')\n",
    "fig.show()"
   ],
   "id": "99fe25fffe04d3aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
